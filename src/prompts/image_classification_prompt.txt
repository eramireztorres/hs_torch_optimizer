You are provided with the following Python model that implements a convolutional neural network (CNN) for image classification using PyTorch:

{current_model_code}

Classification metrics for this model are:
{metrics_str}

Previous models and their performance metrics are:
{history_str}

Additional Information:
{extra_info}

Task:
Based on the given model and its performance, suggest improvements. You may either:
    - Adjust the architecture of the CNN (e.g., add more layers, change the kernel size, modify activation functions).
    - Adjust the hyperparameters of the CNN, such as the number of filters or learning rate.
    - Propose techniques to improve model generalization, such as data augmentation or regularization methods.
    - Introduce advanced techniques like batch normalization, dropout, or residual connections.

**Example 1** (Strong Metrics, Small Adjustment in Filters):
Previous Model:
def load_model(X_train, y_train):
    import torch.nn as nn
    import torch.nn.functional as F
    class SimpleImageClassificationNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleImageClassificationNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, stride=1, padding=1)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (img_height // 4) * (img_width // 4), 128)
            self.fc2 = nn.Linear(128, num_classes)
        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(x.size(0), -1)
            x = F.relu(self.fc1(x))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleImageClassificationNN(num_channels, img_height, img_width, num_classes)

Metrics:
    Global:
        Accuracy: 0.92
        Precision: 0.91
        Recall: 0.91
        F1 Score: 0.91
    Per-Class:
        Precision per class: [0.93, 0.88]
        Recall per class: [0.92, 0.89]
        F1 Score per class: [0.92, 0.88]

Extra Info:
Not available

Suggested Improvement:
Since the model is performing well, a small adjustment to the number of filters may improve accuracy:
def load_model(X_train, y_train):
    import torch.nn as nn
    import torch.nn.functional as F
    class SimpleImageClassificationNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleImageClassificationNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=3, stride=1, padding=1)  # Increased filter size
            self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  # Increased filter size
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(128 * (img_height // 4) * (img_width // 4), 128)
            self.fc2 = nn.Linear(128, num_classes)
        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(x.size(0), -1)
            x = F.relu(self.fc1(x))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleImageClassificationNN(num_channels, img_height, img_width, num_classes)

**Example 2** (Add Dropout to Prevent Overfitting):
Previous Model:
def load_model(X_train, y_train):
    import torch.nn as nn
    import torch.nn.functional as F
    class SimpleImageClassificationNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleImageClassificationNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, stride=1, padding=1)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (img_height // 4) * (img_width // 4), 128)
            self.fc2 = nn.Linear(128, num_classes)
        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(x.size(0), -1)
            x = F.relu(self.fc1(x))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleImageClassificationNN(num_channels, img_height, img_width, num_classes)

Metrics:
    Global:
        Accuracy: 0.88
        Precision: 0.87
        Recall: 0.87
        F1 Score: 0.87
    Per-Class:
        Precision per class: [0.90, 0.84]
        Recall per class: [0.88, 0.83]
        F1 Score per class: [0.89, 0.83]

Extra Info:
Not available

Suggested Improvement:
Add dropout layers to prevent overfitting and improve generalization:
def load_model(X_train, y_train):
    import torch.nn as nn
    import torch.nn.functional as F
    class SimpleImageClassificationNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleImageClassificationNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, stride=1, padding=1)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (img_height // 4) * (img_width // 4), 128)
            self.fc2 = nn.Linear(128, num_classes)
            self.dropout = nn.Dropout(0.5)  # Add dropout
        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(x.size(0), -1)
            x = self.dropout(F.relu(self.fc1(x)))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleImageClassificationNN(num_channels, img_height, img_width, num_classes)

**Example 3** (Data Augmentation):
Previous Model:
def load_model(X_train, y_train):
    import torch.nn as nn
    import torch.nn.functional as F
    class SimpleImageClassificationNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleImageClassificationNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, stride=1, padding=1)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (img_height // 4) * (img_width // 4), 128)
            self.fc2 = nn.Linear(128, num_classes)
        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(x.size(0), -1)
            x = F.relu(self.fc1(x))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleImageClassificationNN(num_channels, img_height, img_width, num_classes)

Metrics:
    Global:
        Accuracy: 0.85
        Precision: 0.85
        Recall: 0.85
        F1 Score: 0.85
    Per-Class:
        Precision per class: [0.87, 0.83]
        Recall per class: [0.85, 0.80]
        F1 Score per class: [0.86, 0.81]

Extra Info:
The training set is relatively small and lacks diversity.

Suggested Improvement:
Use data augmentation to expand the diversity of the training data:
def load_model(X_train, y_train):
    import torch.nn as nn
    import torch.nn.functional as F
    from torchvision import transforms
    class SimpleImageClassificationNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleImageClassificationNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, stride=1, padding=1)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (img_height // 4) * (img_width // 4), 128)
            self.fc2 = nn.Linear(128, num_classes)
            self.transform = transforms.Compose([  # Adding data augmentation
                transforms.RandomHorizontalFlip(),
                transforms.RandomRotation(10),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)
            ])
        def forward(self, x):
            x = self.transform(x)
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(x.size(0), -1)
            x = F.relu(self.fc1(x))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleImageClassificationNN(num_channels, img_height, img_width, num_classes)
    
**Example 4** (Fully Connected Neural Network (FCN) for Low-Resolution Images):
Previous Model:
def load_model(X_train, y_train):
    import torch.nn as nn
    import torch.nn.functional as F
    class SimpleCNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleCNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 16, kernel_size=3, stride=1, padding=1)
            self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(32 * (img_height // 4) * (img_width // 4), 128)
            self.fc2 = nn.Linear(128, num_classes)
        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(x.size(0), -1)
            x = F.relu(self.fc1(x))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleCNN(num_channels, img_height, img_width, num_classes)

Metrics for Model:
    Global:
        Accuracy: 0.75
        Precision: 0.73
        Recall: 0.70
        F1 Score: 0.71
    Per-Class:
        Precision per class: [0.80, 0.60]
        Recall per class: [0.78, 0.55]
        F1 Score per class: [0.79, 0.57]

Extra Info:
    The images in the dataset are very low-resolution, making it difficult for a CNN to learn meaningful spatial features.
    The dataset contains only a small number of samples, increasing the risk of overfitting when using convolutional architectures with many parameters.
    The goal is to improve generalization, especially for the minority class (Class 1), while reducing the model's complexity due to limited spatial information in the low-res images.

Suggested Improvement: Use a Fully Connected Network (FCN) for Low-Resolution Images
Reasoning:
    Since the images have low resolution, there may not be sufficient spatial patterns for the CNN to effectively learn. A fully connected network (FCN) that treats the image as a flattened input can sometimes perform better in such cases, as it focuses on the overall distribution of pixel values instead of relying on local spatial features.
    Additionally, the limited number of samples makes it more likely that the CNN will overfit. Using an FCN reduces model complexity and helps mitigate this.
def load_model(X_train, y_train):
    import torch.nn as nn
    class FCNImageClassificationNN(nn.Module):
        def __init__(self, input_dim, hidden_dim, num_classes=10):
            super(FCNImageClassificationNN, self).__init__()
            self.fc1 = nn.Linear(input_dim, hidden_dim)
            self.fc2 = nn.Linear(hidden_dim, hidden_dim)
            self.fc3 = nn.Linear(hidden_dim, num_classes)
            self.relu = nn.ReLU()
            self.dropout = nn.Dropout(0.5)  # Add dropout to prevent overfitting
        def forward(self, x):
            x = x.view(x.size(0), -1)  # Flatten image to 1D vector
            x = self.fc1(x)
            x = self.relu(x)
            x = self.dropout(self.fc2(x))  # Apply dropout after second layer
            x = self.fc3(x)
            return x
    input_dim = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]  # Flattened input
    hidden_dim = 128
    num_classes = len(set(y_train))
    return FCNImageClassificationNN(input_dim, hidden_dim, num_classes)

**Example 5** (Uses a history of models to suggest improvements):
Previous Model 1:
def load_model(X_train, y_train):
    import torch.nn as nn
    class SimpleCNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleCNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, stride=1, padding=1)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(64 * (img_height // 4) * (img_width // 4), 128)
            self.fc2 = nn.Linear(128, num_classes)
        def forward(self, x):
            x = self.pool(nn.ReLU()(self.conv1(x)))
            x = self.pool(nn.ReLU()(self.conv2(x)))
            x = x.view(x.size(0), -1)
            x = nn.ReLU()(self.fc1(x))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleCNN(num_channels, img_height, img_width, num_classes)
    
Metrics for Model 1:
    Global Accuracy: 0.80
    Per-Class Metrics:
        Class 0 F1 Score: 0.85
        Class 1 F1 Score: 0.70
        
Previous Model 2:
def load_model(X_train, y_train):
    import torch.nn as nn
    class SimpleCNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(SimpleCNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, stride=1, padding=1)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  # Added a third convolutional layer
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(128 * (img_height // 8) * (img_width // 8), 128)
            self.fc2 = nn.Linear(128, num_classes)
        def forward(self, x):
            x = self.pool(nn.ReLU()(self.conv1(x)))
            x = self.pool(nn.ReLU()(self.conv2(x)))
            x = self.pool(nn.ReLU()(self.conv3(x)))
            x = x.view(x.size(0), -1)
            x = nn.ReLU()(self.fc1(x))
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return SimpleCNN(num_channels, img_height, img_width, num_classes)

Metrics for Model 2:
    Global Accuracy: 0.85
    Per-Class Metrics:
        Class 0 F1 Score: 0.87
        Class 1 F1 Score: 0.75

Suggested Improvement Based on Model History:
    From Model 1 to Model 2, the addition of a third convolutional layer improved the overall accuracy, but the gap between Class 0 and Class 1 remains significant. In the next iteration, we will focus on improving generalization by adding batch normalization to help stabilize training, dropout to prevent overfitting, and data augmentation to increase training data diversity.
def load_model(X_train, y_train):
    import torch.nn as nn
    import torch.nn.functional as F
    from torchvision import transforms
    class ImprovedCNN(nn.Module):
        def __init__(self, num_channels, img_height, img_width, num_classes=10):
            super(ImprovedCNN, self).__init__()
            self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, stride=1, padding=1)
            self.bn1 = nn.BatchNorm2d(32)  # Added batch normalization
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
            self.bn2 = nn.BatchNorm2d(64)
            self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
            self.bn3 = nn.BatchNorm2d(128)
            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
            self.fc1 = nn.Linear(128 * (img_height // 8) * (img_width // 8), 128)
            self.fc2 = nn.Linear(128, num_classes)
            self.dropout = nn.Dropout(0.5)  # Added dropout
            self.transform = transforms.Compose([  # Added data augmentation
                transforms.RandomHorizontalFlip(),
                transforms.RandomRotation(10),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)
            ])
        def forward(self, x):
            x = self.transform(x)  # Apply data augmentation
            x = self.pool(F.relu(self.bn1(self.conv1(x))))
            x = self.pool(F.relu(self.bn2(self.conv2(x))))
            x = self.pool(F.relu(self.bn3(self.conv3(x))))
            x = x.view(x.size(0), -1)
            x = F.relu(self.fc1(x))
            x = self.dropout(x)  # Apply dropout
            x = self.fc2(x)
            return x
    num_channels = X_train.shape[1]
    img_height = X_train.shape[2]
    img_width = X_train.shape[3]
    num_classes = len(set(y_train))
    return ImprovedCNN(num_channels, img_height, img_width, num_classes)


Please ensure all necessary imports are included within the function.
Provide only executable Python code for the improved model without any comments, explanations, or markdown formatting.

Output:
Provide only the improved Python code that can replace the current model.

